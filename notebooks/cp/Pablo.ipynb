{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1fe75e-c456-485b-a4ed-2faacf65b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import re\n",
    "import os \n",
    "import json \n",
    "import os\n",
    "import pickle  # You can choose another format if preferred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d1839-8f3b-426d-b258-79f7c3467bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "folderpath = Path(r'F:\\AlterG\\Control\\Data')\n",
    "HeelPathTemplate = r'F:\\AlterG\\Control\\Data\\{}\\Gait\\DevicesData.mat'\n",
    "header_line = 8\n",
    "pattern = r\"\\\\([^\\\\]+)_ik\"\n",
    "base_json_path = r\"F:\\AlterG\\Control\\InverseKinematics\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035242e9-875d-4caa-b44b-01b8b07c692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "concatenated_stride_data = {}\n",
    "all_strides_dict = {'Right': {}, 'Left': {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184821a9-b5fa-481e-919f-74d5866bff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpolate strides to a common length and concatenate them\n",
    "def interpolate_strides(strides, target_length=100):\n",
    "    interpolated_values_list = []\n",
    "    x_new = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    for stride_array in strides:\n",
    "        for stride in stride_array:\n",
    "            if len(stride) < 1:\n",
    "                continue\n",
    "            \n",
    "            x_old = np.linspace(0, 1, len(stride))\n",
    "            \n",
    "            if len(stride) < 4:\n",
    "                interp_func = interp1d(x_old, stride, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            else:\n",
    "                interp_func = interp1d(x_old, stride, kind='cubic', bounds_error=False, fill_value=\"extrapolate\")\n",
    "            \n",
    "            interpolated_values = interp_func(x_new)\n",
    "            interpolated_values_list.append(interpolated_values)\n",
    "    \n",
    "    return np.array(interpolated_values_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e33123-f21b-4d1b-ae16-b100d5268d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot all strides per header in a single plot\n",
    "def plot_stride_list(strideList, side, header):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    strideList (list): List containing the stride data.\n",
    "    side (str): Side of the stride ('Right' or 'Left').\n",
    "    header (str): The header to plot.\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for stride in strideList:\n",
    "        plt.plot(stride, label=f'{side} Side', alpha=0.6)\n",
    "    \n",
    "    plt.title(f'All Strides for {header} ({side} Side)')\n",
    "    plt.xlabel('Sample Points')\n",
    "    plt.ylabel('Values')\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc610430-9276-4aae-aac1-ff6e8db4dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot all interpolated strides per header in a single plot.\n",
    "def plot_interpolated_values(interpolated_values, side, header):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    interpolated_values (ndarray): Array containing the interpolated stride data.\n",
    "    side (str): Side of the stride ('Right' or 'Left').\n",
    "    header (str): The header to plot.\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for stride in interpolated_values:\n",
    "        plt.plot(stride, alpha=0.6, label=f'{side} Side' if side not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    \n",
    "    plt.title(f'Interpolated Strides for {header} ({side} Side)')\n",
    "    plt.xlabel('Sample Points')\n",
    "    plt.ylabel('Values')\n",
    "    #plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1f9ba-d629-42d9-ac0f-f7d2e07cf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot concatenated strides for each header and side\n",
    "def plot_subject(concatenated_stride_data, side, header):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for stride_list in concatenated_stride_data[header][side]:\n",
    "        for stride in stride_list:\n",
    "            plt.plot(stride, alpha=0.6, label=f'{side} Side' if side not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "    \n",
    "    plt.title(f'Individual Strides for {header} ({side} Side) for {trial}')\n",
    "    plt.xlabel('% Gait Cycle')\n",
    "    plt.ylabel(f'{header} (deg)')\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca633953-b463-4873-a9d7-4cf43b38466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot mean and standard deviation for each header and side\n",
    "def plot_mean_std(concatenated_stride_data):\n",
    "    mean_strides_dict = {}\n",
    "    std_strides_dict = {}\n",
    "\n",
    "    for side in ['Right', 'Left']:\n",
    "        mean_strides_dict[side] = {}\n",
    "        std_strides_dict[side] = {}\n",
    "\n",
    "        for header in concatenated_stride_data:\n",
    "            all_strides_array = np.concatenate(concatenated_stride_data[header][side])\n",
    "            mean_strides_dict[side][header] = np.mean(all_strides_array, axis=0)\n",
    "            std_strides_dict[side][header] = np.std(all_strides_array, axis=0)\n",
    "\n",
    "    # Plot mean with standard deviation shaded region for each header and side\n",
    "    plot_handles = []\n",
    "    for side in ['Right', 'Left']:\n",
    "        for header in mean_strides_dict[side]:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plot_handle, = plt.plot(mean_strides_dict[side][header], label=f'{side} Side')\n",
    "            plt.fill_between(np.arange(len(mean_strides_dict[side][header])),\n",
    "                             mean_strides_dict[side][header] - std_strides_dict[side][header],\n",
    "                             mean_strides_dict[side][header] + std_strides_dict[side][header],\n",
    "                             alpha=0.3)\n",
    "            plt.title(f'{header} ({side} Side) for {trial}')\n",
    "            plt.xlabel('% Gait Cycle')\n",
    "            plt.ylabel(f'{header} (deg)')\n",
    "            #plt.legend()\n",
    "            plot_handles.append(plot_handle)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    return plot_handles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173e160-07ef-47fb-bd9e-7f4908bb9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length of each stride and then their mean and standard deviation\n",
    "def clean_strides_mean_std(stride_list):\n",
    "    lengths = [len(stride) for stride in stride_list]\n",
    "    mean_length = np.mean(lengths)\n",
    "    std_length = np.std(lengths)\n",
    "    \n",
    "    # Calculate the minimum acceptable length\n",
    "    min_length = mean_length - std_length\n",
    "    # Filter out strides that are shorter than the minimum acceptable length\n",
    "    cleaned_strides = [stride for stride in stride_list if len(stride) >= min_length]\n",
    "    \n",
    "    return cleaned_strides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd76e21-48c9-4e20-85cf-34cdda2787a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the interquartile range\n",
    "def clean_strides_iqr(stride_list):\n",
    "    lengths = [len(stride) for stride in stride_list]\n",
    "    \n",
    "    # Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "    Q1 = np.percentile(lengths, 25)\n",
    "    Q3 = np.percentile(lengths, 75)\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate the lower bound for acceptable lengths\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    # Filter out strides that are shorter than the lower bound\n",
    "    cleaned_strides = [stride for stride in stride_list if len(stride) >= lower_bound]\n",
    "    \n",
    "    return cleaned_strides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc75d5-bc0d-4e40-95ca-926e1b52c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to json files\n",
    "def save_data_to_json(data, filepath):\n",
    "    json_data = {header: {'Right': [arr.tolist() for arr in data[header]['Right']],\n",
    "                          'Left': [arr.tolist() for arr in data[header]['Left']]}\n",
    "                 for header in data}\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(json_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc501abf-0c3f-42d5-b5d3-a44a0a6e3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect if the stride data is upside down and flip it\n",
    "def correct_orientation(data_array):\n",
    "    if np.mean(data_array) < 0:  # Assuming that correct data has positive mean\n",
    "        return -data_array\n",
    "    return data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d6cd2-d5be-4d10-bcf1-b7518be0bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def process_side_strides(heels, header, data):\n",
    " #   strideList = []\n",
    "  #  for idx in range(len(heels) - 1):\n",
    "   #     start_index = int(heels[idx][0]) if hasattr(heels[idx], '__iter__') else int(heels[idx])\n",
    "    #    end_index = int(heels[idx + 1][0]) if hasattr(heels[idx + 1], '__iter__') else int(heels[idx + 1])\n",
    "        \n",
    "        # Ensure indices are valid\n",
    "     #   if start_index < end_index:\n",
    "      #      stride_data = data.iloc[start_index:end_index][header].values\n",
    "       #     stride_data = correct_orientation(stride_data)  # Correct orientation if necessary\n",
    "        #    strideList.append(stride_data)\n",
    "            \n",
    "    #return strideList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd1313-9dda-4c19-8c76-d827b2b5325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_stride_phases(heel_indices, toe_indices, contralateral_heel_indices, contralateral_toe_indices, header, data, side, target_length=100):\n",
    "    phase_normalized_strides = []\n",
    "    phase_labels = []\n",
    "    num_strides = len(heel_indices) - 1\n",
    "\n",
    "    for idx in range(num_strides):\n",
    "        start_idx = int(heel_indices[idx])\n",
    "        end_idx = int(heel_indices[idx + 1])\n",
    "        print(f\"\\nProcessing stride {idx + 1}/{num_strides}\")#########\n",
    "        if start_idx >= end_idx:\n",
    "            continue\n",
    "        print(f\"Start index: {start_idx}, End index: {end_idx}\")#####\n",
    "        stride_data = data.iloc[start_idx:end_idx][header].values\n",
    "        stride_length = len(stride_data)\n",
    "\n",
    "        if stride_length < 2:\n",
    "            print(\"Invalid stride (start_idx >= end_idx). Skipping.\")####\n",
    "            continue\n",
    "\n",
    "        # Find contralateral toe-off candidates\n",
    "        contralateral_toe_off_candidates = [toe for toe in contralateral_toe_indices if start_idx < toe < end_idx]\n",
    "        if not contralateral_toe_off_candidates:\n",
    "            continue\n",
    "        contralateral_toe_off = int(min(contralateral_toe_off_candidates, key=lambda x: abs(x - start_idx)))\n",
    "\n",
    "        # Find contralateral heel contact candidates\n",
    "        contralateral_heel_candidates = [heel for heel in contralateral_heel_indices if start_idx < heel < end_idx]\n",
    "        if not contralateral_heel_candidates:\n",
    "            continue\n",
    "        contralateral_heel_contact = int(min(contralateral_heel_candidates, key=lambda x: abs(x - contralateral_toe_off)))\n",
    "       \n",
    "        # Find ipsilateral toe-off as the toe index closest to start_idx\n",
    "        ipsilateral_toe_off_candidates = [toe for toe in toe_indices if start_idx < toe < end_idx]\n",
    "        if not ipsilateral_toe_off_candidates:\n",
    "            continue\n",
    "        ipsilateral_toe_off = int(min(ipsilateral_toe_off_candidates, key=lambda x: abs(x - start_idx)))\n",
    "\n",
    "        # Segment the phases\n",
    "        lr_segment = stride_data[0 : contralateral_toe_off - start_idx]\n",
    "        mtst_segment = stride_data[contralateral_toe_off - start_idx : contralateral_heel_contact - start_idx]\n",
    "        ps_segment = stride_data[contralateral_heel_contact - start_idx : ipsilateral_toe_off - start_idx]\n",
    "\n",
    "        # Check for empty segments before interpolation\n",
    "        if len(lr_segment) == 0 or len(mtst_segment) == 0 or len(ps_segment) == 0:\n",
    "            continue\n",
    "\n",
    "        # Normalize each phase individually\n",
    "        lr_normalized = normalize_segment(lr_segment, 12)\n",
    "        mtst_normalized = normalize_segment(mtst_segment, 38)\n",
    "        ps_normalized = normalize_segment(ps_segment, 12)\n",
    "\n",
    "        # Find the ipsilateral heel contact of the next stride for the remaining segment\n",
    "        if idx + 1 < num_strides:\n",
    "            next_start_idx = int(heel_indices[idx + 1])\n",
    "            remaining_segment = data.iloc[ipsilateral_toe_off:next_start_idx][header].values\n",
    "        else:\n",
    "            remaining_segment = []\n",
    "\n",
    "        # Normalize remaining segment to 38 points\n",
    "        if len(remaining_segment) > 0:\n",
    "            remaining_normalized = normalize_segment(remaining_segment, 38)\n",
    "            final_normalized_stride = np.concatenate([lr_normalized, mtst_normalized, ps_normalized, remaining_normalized])\n",
    "        else:\n",
    "            final_normalized_stride = np.concatenate([lr_normalized, mtst_normalized, ps_normalized])\n",
    "\n",
    "        # Ensure the final length is 100 points\n",
    "        if len(final_normalized_stride) < target_length:\n",
    "            remaining_length = target_length - len(final_normalized_stride)\n",
    "            final_normalized_stride = np.concatenate([final_normalized_stride, np.zeros(remaining_length)])\n",
    "        elif len(final_normalized_stride) > target_length:\n",
    "            final_normalized_stride = final_normalized_stride[:target_length]\n",
    "\n",
    "        phase_normalized_strides.append(final_normalized_stride)\n",
    "        phase_labels.append((12, 38, 12, len(remaining_segment)))\n",
    "\n",
    "    return phase_normalized_strides, phase_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaad9ced-e339-43d9-b6ec-87ca77a1161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_segment(segment, target_length):\n",
    "    if len(segment) < 1:\n",
    "        return np.zeros(target_length)\n",
    "    \n",
    "    x_new = np.linspace(0, 1, target_length)\n",
    "    x_old = np.linspace(0, 1, len(segment))\n",
    "    \n",
    "    if len(segment) < 4:\n",
    "        interp_func = interp1d(x_old, segment, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "    else:\n",
    "        interp_func = interp1d(x_old, segment, kind='cubic', bounds_error=False, fill_value=\"extrapolate\")\n",
    "    \n",
    "    return interp_func(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696120d-792c-4729-93ae-ef14bc6ee183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalized_strides(phase_normalized_strides_r, phase_normalized_strides_l, header, phase_labels_r, phase_labels_l):\n",
    "    # Determine the min and max values across both Right and Left side strides\n",
    "    min_r = min([min(stride) for stride in phase_normalized_strides_r])\n",
    "    max_r = max([max(stride) for stride in phase_normalized_strides_r])\n",
    "    min_l = min([min(stride) for stride in phase_normalized_strides_l])\n",
    "    max_l = max([max(stride) for stride in phase_normalized_strides_l])\n",
    "\n",
    "    # Determine the common min and max values for y-axis\n",
    "    common_min = (min(min_r, min_l) - 2)\n",
    "    common_max = (max(max_r, max_l) + 2)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Right side\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for stride in phase_normalized_strides_r:\n",
    "        if len(stride) == 100:  # Ensure that the stride is fully normalized\n",
    "            plt.plot(stride, alpha=0.7)\n",
    "        else:\n",
    "            print(f\"Stride length for right side is not 100: {len(stride)}\")\n",
    "    plt.title(f'{header} - Right Side')\n",
    "    plt.xlabel('Normalized Points')\n",
    "    plt.ylabel(header)\n",
    "    plt.axvline(x=12, color='r', linestyle='--', label='LR end')\n",
    "    plt.axvline(x=50, color='r', linestyle='--', label='MTSt end')\n",
    "    plt.axvline(x=62, color='r', linestyle='--', label='PS end')\n",
    "\n",
    "    # Set the same y-axis limits for both subplots\n",
    "    plt.ylim([common_min, common_max])\n",
    "\n",
    "    # Plot Left side\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for stride in phase_normalized_strides_l:\n",
    "        if len(stride) == 100:  # Ensure that the stride is fully normalized\n",
    "            plt.plot(stride, alpha=0.7)\n",
    "        else:\n",
    "            print(f\"Stride length for left side is not 100: {len(stride)}\")\n",
    "    plt.title(f'{header} - Left Side')\n",
    "    plt.xlabel('Normalized Points')\n",
    "    plt.ylabel(header)\n",
    "    plt.axvline(x=12, color='r', linestyle='--', label='LR end')\n",
    "    plt.axvline(x=50, color='r', linestyle='--', label='MTSt end')\n",
    "    plt.axvline(x=62, color='r', linestyle='--', label='PS end')\n",
    "\n",
    "    # Set the same y-axis limits for both subplots\n",
    "    plt.ylim([common_min, common_max])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195c1e6-d80e-4b6f-aab0-cd287197cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ROI (file, trial_name):\n",
    "    print ('ROI = ', file['NexusData'][trial_name]['Info']['Region'][:])\n",
    "    return file['NexusData'][trial_name]['Info']['Region'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d03db5-e93c-4306-ada4-05fe62af0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_rate(file, trial_name):\n",
    "    import numpy as np\n",
    "    trial_data = file['NexusData'][trial_name]\n",
    "\n",
    "    # Check if 'HeelType' exists in trial_data\n",
    "    if 'HeelType' in trial_data:\n",
    "        heel_type_data = trial_data['HeelType'][()]\n",
    "        if isinstance(heel_type_data, bytes):\n",
    "            heel_type = heel_type_data.decode('utf-8')\n",
    "        elif isinstance(heel_type_data, np.ndarray):\n",
    "            heel_type = ''.join(chr(code) for code in heel_type_data.flatten())\n",
    "        else:\n",
    "            heel_type = str(heel_type_data)\n",
    "        print(f\"HeelType: {heel_type}\")\n",
    "\n",
    "        if heel_type == 'IMUs':\n",
    "            devices = trial_data['devices']\n",
    "            # Find the first IMU device starting with 'TS0'\n",
    "            imu_devices = [name for name in devices if name.startswith('TS0')]\n",
    "            if not imu_devices:\n",
    "                print('No IMU devices found starting with TS0. Using default sampling rate of 225 Hz.')\n",
    "                return 225  # Default value\n",
    "            imu_device = imu_devices[0]\n",
    "            imu_device_data = devices[imu_device]\n",
    "\n",
    "            if 'accel_x' in imu_device_data and 'Rate' in imu_device_data['accel_x']:\n",
    "                sampling_rate = imu_device_data['accel_x']['Rate'][()]\n",
    "                sampling_rate = np.array(sampling_rate).item()\n",
    "                print('IMU heels Sampling =', sampling_rate)\n",
    "                return sampling_rate\n",
    "            else:\n",
    "                print(f\"Could not find 'Rate' under 'accel_x' in IMU device '{imu_device}'. Using default sampling rate of 225 Hz.\")\n",
    "                return 225  # Default value\n",
    "\n",
    "        elif heel_type == 'Kinematics':\n",
    "            print('Kinematic Heels = 100 Hz conversion')\n",
    "            return 100\n",
    "        else:\n",
    "            print('Unknown HeelType:', heel_type)\n",
    "            print('No definition of heel type; defaulting to 225 Hz conversion')\n",
    "            return 225\n",
    "    else:\n",
    "        # 'HeelType' does not exist in trial_data\n",
    "        print(\"HeelType does not exist in trial_data. Using default sampling rate of 225 Hz.\")\n",
    "        return 225  # Default sampling rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d08ee-3b78-451c-8d60-a043e883355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_time(indices, sampling_rate, frame_offset=0):\n",
    "    \"\"\"\n",
    "    Convert a list of indices to times in seconds based on the sampling rate.\n",
    "    \n",
    "    Parameters:\n",
    "    - indices: list or array of indices (frame numbers).\n",
    "    - sampling_rate: sampling rate in Hz.\n",
    "    - frame_offset: frame offset to adjust indices if needed (default is 0).\n",
    "    \n",
    "    Returns:\n",
    "    - times: list of times in seconds corresponding to the indices.\n",
    "    \"\"\"\n",
    "    print('Indices = ', indices)\n",
    "    indices = np.array(indices).flatten()\n",
    "    indices = indices.tolist()\n",
    "    times = [(idx - frame_offset) / sampling_rate for idx in indices]\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066194de-da97-4485-8f6a-931c30d7dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events_within_roi(events, ROI, event_sampling_rate):\n",
    "    \"\"\"\n",
    "    Filters event indices to include only those within the ROI, handling the conversion\n",
    "    between the ROI sampling rate (100 Hz) and the event sampling rate.\n",
    "    \"\"\"\n",
    "    # Extract start and end frames from ROI\n",
    "    roi_start_frame_100hz = ROI[0][0]\n",
    "    roi_end_frame_100hz = ROI[1][0]\n",
    "    \n",
    "    # Convert ROI frames to time (seconds) using 100 Hz sampling rate\n",
    "    roi_start_time = roi_start_frame_100hz / 100.0\n",
    "    roi_end_time = roi_end_frame_100hz / 100.0\n",
    "    #print(f\"Start and end times: {roi_start_time} {roi_end_time}\")\n",
    "    \n",
    "    # Ensure events is a 1D NumPy array of scalars\n",
    "    events = np.array(events).flatten()\n",
    "    \n",
    "    # Convert event indices to time (seconds) using event_sampling_rate\n",
    "    event_times = events / event_sampling_rate\n",
    "    \n",
    "    # Filter event times within ROI times using a boolean mask\n",
    "    mask = (event_times >= roi_start_time) & (event_times <= roi_end_time)\n",
    "    filtered_event_times = event_times[mask]\n",
    "    \n",
    "    # Convert filtered event times back to indices at event_sampling_rate\n",
    "    filtered_events = np.round(filtered_event_times * event_sampling_rate).astype(int)\n",
    "    \n",
    "    # Convert to list\n",
    "    filtered_events = np.array(filtered_events).flatten().tolist()\n",
    "    \n",
    "    return filtered_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64221a-a72f-4712-a7d3-131ed99b85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_side_strides(ipsi_heels, ipsi_toes, contra_heels, contra_toes, header, data):\n",
    "    \"\"\"\n",
    "    Processes strides for one side and collects associated events.\n",
    "\n",
    "    Parameters:\n",
    "    - ipsi_heels: list of ipsilateral heel strike times (seconds).\n",
    "    - ipsi_toes: list of ipsilateral toe-off times (seconds).\n",
    "    - contra_heels: list of contralateral heel strike times (seconds).\n",
    "    - contra_toes: list of contralateral toe-off times (seconds).\n",
    "    - header: string, the column name in data to process.\n",
    "    - data: pandas DataFrame containing the data with a 'Time' column.\n",
    "\n",
    "    Returns:\n",
    "    - strideList: list of dictionaries, each containing stride data and events.\n",
    "    \"\"\"\n",
    "    # Function to get indices from times\n",
    "    def get_indices_from_times(event_times, data_times):\n",
    "        indices = []\n",
    "        for t in event_times:\n",
    "            idx = np.argmin(np.abs(data_times - t))\n",
    "            indices.append(idx)\n",
    "            # Print event time, index, and corresponding data time\n",
    "            #print(f\"Event Time: {t:.6f}, Index: {idx}, Data Time at Index: {data_times[idx]:.6f}\")\n",
    "        return indices\n",
    "\n",
    "\n",
    "    strideList = []\n",
    "\n",
    "    # Extract data times\n",
    "    data_times = data['time'].values\n",
    "\n",
    "    # Convert event times to indices\n",
    "    ipsi_heel_indices = get_indices_from_times(ipsi_heels, data_times)\n",
    "    ipsi_toe_indices = get_indices_from_times(ipsi_toes, data_times)\n",
    "    contra_heel_indices = get_indices_from_times(contra_heels, data_times)\n",
    "    contra_toe_indices = get_indices_from_times(contra_toes, data_times)\n",
    "\n",
    "    for idx in range(len(ipsi_heel_indices) - 1):\n",
    "        start_idx = ipsi_heel_indices[idx]\n",
    "        end_idx = ipsi_heel_indices[idx + 1]\n",
    "        start_time = data_times[start_idx]\n",
    "        end_time = data_times[end_idx]\n",
    "        #print(f'\\nStride {idx + 1}: Start Time = {start_time:.3f}s, End Time = {end_time:.3f}s')\n",
    "\n",
    "        # Extract stride data between start_idx and end_idx\n",
    "        stride_data = data.iloc[start_idx:end_idx][header].values\n",
    "        stride_time = data.iloc[start_idx:end_idx]['time'].values\n",
    "\n",
    "        # Print stride data length and a sample\n",
    "        #print(f'Stride Data Length: {len(stride_data)}')\n",
    "        if len(stride_data) > 0:\n",
    "            pass\n",
    "        else:\n",
    "            print('No stride data found for this stride.')\n",
    "            continue  # Skip to the next stride if there's no data\n",
    "\n",
    "        events_in_stride = []\n",
    "        all_events = []\n",
    "        for t in ipsi_toes:\n",
    "            if start_time <= t <= end_time:\n",
    "                all_events.append({'time': t, 'type': 'ipsi_toe_off'})\n",
    "        # Contralateral events\n",
    "        for t in contra_toes:\n",
    "            if start_time <= t <= end_time:\n",
    "                all_events.append({'time': t, 'type': 'contra_toe_off'})\n",
    "        for t in contra_heels:\n",
    "            if start_time <= t <= end_time:\n",
    "                all_events.append({'time': t, 'type': 'contra_heel_strike'})\n",
    "\n",
    "        # Sort events by time to maintain sequence\n",
    "        all_events.sort(key=lambda x: x['time'])\n",
    "\n",
    "        # Calculate event indices relative to stride_data\n",
    "        for event in all_events:\n",
    "            relative_time = (event['time'] - start_time) / (end_time - start_time)\n",
    "            event_idx = int(relative_time * (len(stride_data) - 1))\n",
    "            event['index'] = event_idx\n",
    "            events_in_stride.append(event)\n",
    "\n",
    "        # Correct orientation if necessary\n",
    "        stride_data = correct_orientation(stride_data)\n",
    "\n",
    "        # Store stride data and events\n",
    "        stride_info = {\n",
    "            'stride_data': stride_data,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'events': events_in_stride\n",
    "        }\n",
    "\n",
    "        strideList.append(stride_info)\n",
    "\n",
    "    return strideList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f184a3a-0e21-43a1-9e22-8ddd3fdf891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strides(strides_r, strides_l, header, header_type, plot_style='single', use_normalized_data=True):\n",
    "    \"\"\"\n",
    "    Plots the strides for the given header and header type, including gait events.\n",
    "\n",
    "    Parameters:\n",
    "    - strides_r: list of stride_info dictionaries for the right side (or None)\n",
    "    - strides_l: list of stride_info dictionaries for the left side (or None)\n",
    "    - header: the header name\n",
    "    - header_type: 'bilateral', 'right_only', 'left_only'\n",
    "    - plot_style: 'single' or 'side_by_side'\n",
    "    - use_normalized_data: Boolean indicating whether to use normalized data\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Define event markers and colors\n",
    "    event_markers = {\n",
    "        'ipsi_toe_off': {'marker': 'o', 'color': 'green', 'label': 'Ipsi Toe Off'},\n",
    "        'contra_toe_off': {'marker': 'x', 'color': 'purple', 'label': 'Contra Toe Off'},\n",
    "        'contra_heel_strike': {'marker': '^', 'color': 'orange', 'label': 'Contra Heel Strike'},\n",
    "    }\n",
    "\n",
    "    def plot_events(stride_info, stride_data, x_values, use_normalized_data):\n",
    "        \"\"\"\n",
    "        Plots the gait events on the stride data.\n",
    "\n",
    "        Parameters:\n",
    "        - stride_info: Dictionary containing stride information.\n",
    "        - stride_data: The stride data to plot.\n",
    "        - x_values: The x-axis values corresponding to stride_data.\n",
    "        - use_normalized_data: Boolean indicating whether to use normalized event indices.\n",
    "        \"\"\"\n",
    "        # Select events and indices based on whether normalized data is used\n",
    "        if use_normalized_data:\n",
    "            events = stride_info.get('normalized_events', stride_info['events'])\n",
    "            for event in events:\n",
    "                idx = event.get('normalized_index')\n",
    "                event_type = event['type']\n",
    "                marker_info = event_markers.get(event_type, {'marker': 'd', 'color': 'black', 'label': event_type})\n",
    "                if idx is not None and 0 <= idx < len(x_values):\n",
    "                    plt.plot(x_values[idx], stride_data[idx], marker=marker_info['marker'], color=marker_info['color'],\n",
    "                             markersize=8, label=marker_info['label'])\n",
    "        else:\n",
    "            events = stride_info['events']\n",
    "            for event in events:\n",
    "                idx = event['index']\n",
    "                event_type = event['type']\n",
    "                marker_info = event_markers.get(event_type, {'marker': 'd', 'color': 'black', 'label': event_type})\n",
    "                if idx is not None and 0 <= idx < len(x_values):\n",
    "                    plt.plot(x_values[idx], stride_data[idx], marker=marker_info['marker'], color=marker_info['color'],\n",
    "                             markersize=8, label=marker_info['label'])\n",
    "\n",
    "    # Begin plotting\n",
    "    if header_type == 'bilateral':\n",
    "        if plot_style == 'single':\n",
    "            plt.figure()\n",
    "            # Plot right strides in red\n",
    "            for stride_info in strides_r:\n",
    "                if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                    stride_data = stride_info['normalized_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))  # Stride percentage\n",
    "                else:\n",
    "                    stride_data = stride_info['stride_data']\n",
    "                    x_values = np.arange(len(stride_data))\n",
    "                plt.plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "                plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "            # Plot left strides in blue\n",
    "            for stride_info in strides_l:\n",
    "                if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                    stride_data = stride_info['normalized_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                else:\n",
    "                    stride_data = stride_info['stride_data']\n",
    "                    x_values = np.arange(len(stride_data))\n",
    "                plt.plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "                plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "            plt.title(f'Bilateral Strides - {header}')\n",
    "            plt.xlabel('Stride Percentage (%)' if use_normalized_data else 'Sample Points')\n",
    "            plt.ylabel(header)\n",
    "            # Remove duplicate legend entries\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            plt.legend(by_label.values(), by_label.keys())\n",
    "            plt.show()\n",
    "\n",
    "        elif plot_style == 'side_by_side':\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            # Plot right strides\n",
    "            for stride_info in strides_r:\n",
    "                if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                    stride_data = stride_info['normalized_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                else:\n",
    "                    stride_data = stride_info['stride_data']\n",
    "                    x_values = np.arange(len(stride_data))\n",
    "                axs[0].plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "                # Plot events\n",
    "                plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "            axs[0].set_title(f'Right Strides - {header}')\n",
    "            axs[0].set_xlabel('Stride Percentage (%)' if use_normalized_data else 'Sample Points')\n",
    "            axs[0].set_ylabel(header)\n",
    "\n",
    "            # Plot left strides\n",
    "            for stride_info in strides_l:\n",
    "                if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                    stride_data = stride_info['normalized_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                else:\n",
    "                    stride_data = stride_info['stride_data']\n",
    "                    x_values = np.arange(len(stride_data))\n",
    "                axs[1].plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "                # Plot events\n",
    "                plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "            axs[1].set_title(f'Left Strides - {header}')\n",
    "            axs[1].set_xlabel('Stride Percentage (%)' if use_normalized_data else 'Sample Points')\n",
    "            axs[1].set_ylabel(header)\n",
    "\n",
    "            # Adjust layout and show plot\n",
    "            plt.tight_layout()\n",
    "            # Remove duplicate legend entries\n",
    "            handles, labels = axs[0].get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            axs[0].legend(by_label.values(), by_label.keys())\n",
    "            plt.show()\n",
    "\n",
    "    elif header_type == 'right_only':\n",
    "        plt.figure()\n",
    "        for stride_info in strides_r:\n",
    "            if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                stride_data = stride_info['normalized_stride_data']\n",
    "                x_values = np.linspace(0, 100, len(stride_data))\n",
    "            else:\n",
    "                stride_data = stride_info['stride_data']\n",
    "                x_values = np.arange(len(stride_data))\n",
    "            plt.plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "            plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "        plt.title(f'Right Strides - {header}')\n",
    "        plt.xlabel('Stride Percentage (%)' if use_normalized_data else 'Sample Points')\n",
    "        plt.ylabel(header)\n",
    "        # Remove duplicate legend entries\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        plt.legend(by_label.values(), by_label.keys())\n",
    "        plt.show()\n",
    "\n",
    "    elif header_type == 'left_only':\n",
    "        plt.figure()\n",
    "        for stride_info in strides_l:\n",
    "            if use_normalized_data and 'normalized_stride_data' in stride_info:\n",
    "                stride_data = stride_info['normalized_stride_data']\n",
    "                x_values = np.linspace(0, 100, len(stride_data))\n",
    "            else:\n",
    "                stride_data = stride_info['stride_data']\n",
    "                x_values = np.arange(len(stride_data))\n",
    "            plt.plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "            plot_events(stride_info, stride_data, x_values, use_normalized_data)\n",
    "\n",
    "        plt.title(f'Left Strides - {header}')\n",
    "        plt.xlabel('Stride Percentage (%)' if use_normalized_data else 'Sample Points')\n",
    "        plt.ylabel(header)\n",
    "        # Remove duplicate legend entries\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        plt.legend(by_label.values(), by_label.keys())\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f6c83-4b54-4341-a9a5-d5486b46f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_strides(strides_list, normalization_type='cycle', target_length=100):\n",
    "    \"\"\"\n",
    "    Normalizes strides based on the specified normalization type.\n",
    "\n",
    "    Parameters:\n",
    "    - strides_list: List of stride_info dictionaries.\n",
    "    - normalization_type: 'cycle' or 'phase'.\n",
    "    - target_length: Integer, the target length for normalization.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_strides_list: List of stride_info dictionaries with normalized stride_data and adjusted events.\n",
    "    \"\"\"\n",
    "    normalized_strides_list = []\n",
    "\n",
    "    for stride_info in strides_list:\n",
    "        stride_data = stride_info['stride_data']\n",
    "        stride_length = len(stride_data)\n",
    "\n",
    "        if normalization_type == 'cycle':\n",
    "            # Normalize stride data to target_length using interpolation\n",
    "            stride_data_normalized = np.interp(\n",
    "                np.linspace(0, stride_length - 1, target_length),\n",
    "                np.arange(stride_length),\n",
    "                stride_data\n",
    "            )\n",
    "\n",
    "            # Adjust event indices\n",
    "            adjusted_events = []\n",
    "            for event in stride_info['events']:\n",
    "                original_index = event['index']\n",
    "                normalized_index = int((original_index / (stride_length - 1)) * (target_length - 1))\n",
    "                event_adjusted = event.copy()\n",
    "                event_adjusted['index'] = normalized_index\n",
    "                adjusted_events.append(event_adjusted)\n",
    "\n",
    "            # Update stride_info with normalized data and adjusted events\n",
    "            stride_info_normalized = stride_info.copy()\n",
    "            stride_info_normalized['normalized_stride_data'] = stride_data_normalized\n",
    "            stride_info_normalized['normalized_events'] = adjusted_events\n",
    "\n",
    "        elif normalization_type == 'phase':\n",
    "            # Placeholder for 'phase' normalization (to be developed)\n",
    "            stride_info_normalized = stride_info  # No changes for now\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid normalization_type. Choose 'cycle' or 'phase'.\")\n",
    "\n",
    "        normalized_strides_list.append(stride_info_normalized)\n",
    "\n",
    "    return normalized_strides_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6210fd8-6fb8-4a8d-ad30-1f7c4ba33bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_conventions(strides_r, strides_l, header):\n",
    "    \"\"\"\n",
    "    Applies the required processing to the strides for the given header.\n",
    "\n",
    "    Parameters:\n",
    "    - strides_r: List of stride_info dictionaries for the right side (or None).\n",
    "    - strides_l: List of stride_info dictionaries for the left side (or None).\n",
    "    - header: The header name (string).\n",
    "\n",
    "    Returns:\n",
    "    - strides_r: Processed strides for the right side.\n",
    "    - strides_l: Processed strides for the left side.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Headers to skip\n",
    "    skip_headers = [\n",
    "        'time', 'pelvis_tilt', 'pelvis_list', 'pelvis_tx', 'pelvis_ty', 'pelvis_tz',\n",
    "        'hip_rotation_r', 'hip_rotation_l', 'subtalar_angle_l', 'subtalar_angle_r',\n",
    "        'mtp_angle_l', 'mtp_angle_r'\n",
    "    ]\n",
    "\n",
    "    if header in skip_headers:\n",
    "        # Copy normalized data to processed data without changes\n",
    "        if strides_r is not None:\n",
    "            for stride_info in strides_r:\n",
    "                stride_info['processed_stride_data'] = stride_info['normalized_stride_data']\n",
    "        if strides_l is not None:\n",
    "            for stride_info in strides_l:\n",
    "                stride_info['processed_stride_data'] = stride_info['normalized_stride_data']\n",
    "        return strides_r, strides_l\n",
    "\n",
    "    # Headers where right strides need to be multiplied by -1\n",
    "    headers_flip_right = ['pelvis_rotation', 'lumbar_bending', 'lumbar_rotation']\n",
    "\n",
    "    # Headers where both sides need to be multiplied by -1\n",
    "    headers_multiply_minus1 = ['lumbar_extension']\n",
    "\n",
    "    # Headers where we need to check for flipped strides\n",
    "    headers_check_flip = ['hip_flexion', 'knee_angle', 'ankle_angle']\n",
    "\n",
    "    # Process right strides\n",
    "    if strides_r is not None:\n",
    "        # Collect all normalized stride data for right side\n",
    "        all_stride_data_r = [stride_info['normalized_stride_data'] for stride_info in strides_r]\n",
    "\n",
    "        for stride_info in strides_r:\n",
    "            # Start with a copy of the normalized data\n",
    "            stride_data = stride_info['normalized_stride_data'].copy()\n",
    "\n",
    "            # Apply conventions\n",
    "            if header in headers_flip_right:\n",
    "                stride_data = -stride_data\n",
    "\n",
    "            if header in headers_multiply_minus1:\n",
    "                stride_data = -stride_data\n",
    "\n",
    "            if any(h in header for h in headers_check_flip) or header == 'hip_adduction_r':\n",
    "                # Correct flipped strides using correlation with mean stride\n",
    "                stride_data = correct_flipped_stride(stride_data, all_stride_data_r)\n",
    "\n",
    "            # Demean if necessary\n",
    "            if header == 'pelvis_rotation':\n",
    "                mean_value = np.mean(stride_data)\n",
    "                stride_data -= mean_value\n",
    "\n",
    "            # Store the processed data\n",
    "            stride_info['processed_stride_data'] = stride_data\n",
    "\n",
    "    # Process left strides similarly\n",
    "    if strides_l is not None:\n",
    "        # Collect all normalized stride data for left side\n",
    "        all_stride_data_l = [stride_info['normalized_stride_data'] for stride_info in strides_l]\n",
    "\n",
    "        for stride_info in strides_l:\n",
    "            # Start with a copy of the normalized data\n",
    "            stride_data = stride_info['normalized_stride_data'].copy()\n",
    "\n",
    "            # Apply conventions\n",
    "            if header in headers_multiply_minus1:\n",
    "                stride_data = -stride_data\n",
    "\n",
    "            if any(h in header for h in headers_check_flip) or header == 'hip_adduction_l':\n",
    "                # Correct flipped strides using correlation with mean stride\n",
    "                stride_data = correct_flipped_stride(stride_data, all_stride_data_l)\n",
    "\n",
    "            # Demean if necessary\n",
    "            if header == 'pelvis_rotation':\n",
    "                mean_value = np.mean(stride_data)\n",
    "                stride_data -= mean_value\n",
    "\n",
    "            # Store the processed data\n",
    "            stride_info['processed_stride_data'] = stride_data\n",
    "\n",
    "    return strides_r, strides_l\n",
    "\n",
    "\n",
    "\n",
    "def correct_flipped_stride(stride_data, all_stride_data_list):\n",
    "    \"\"\"\n",
    "    Identifies and corrects a single stride if it is flipped, based on correlation with the mean stride.\n",
    "\n",
    "    Parameters:\n",
    "    - stride_data: Numpy array of stride data.\n",
    "    - all_stride_data_list: List of numpy arrays containing all stride data.\n",
    "\n",
    "    Returns:\n",
    "    - corrected_stride_data: Corrected stride data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the mean stride from all strides\n",
    "    all_strides_array = np.stack(all_stride_data_list, axis=0)\n",
    "    mean_stride = np.mean(all_strides_array, axis=0)\n",
    "\n",
    "    # Compute the correlation coefficient between the stride and the mean stride\n",
    "    correlation = np.corrcoef(stride_data, mean_stride)[0, 1]\n",
    "\n",
    "    # If the correlation is negative, flip the stride\n",
    "    if correlation < 0:\n",
    "        corrected_stride_data = -stride_data\n",
    "    else:\n",
    "        corrected_stride_data = stride_data\n",
    "\n",
    "    return corrected_stride_data\n",
    "\n",
    "\n",
    "def correct_flipped_stride_hip_adduction(stride_data):\n",
    "    \"\"\"\n",
    "    Identifies and corrects a single hip adduction stride if it is flipped.\n",
    "\n",
    "    Parameters:\n",
    "    - stride_data: Numpy array of stride data.\n",
    "\n",
    "    Returns:\n",
    "    - stride_data: Corrected stride data.\n",
    "    \"\"\"\n",
    "    # Analyze values at specific points\n",
    "    idx_20 = int(0.2 * len(stride_data))\n",
    "    idx_80 = int(0.8 * len(stride_data))\n",
    "    value_20 = stride_data[idx_20]\n",
    "    value_80 = stride_data[idx_80]\n",
    "    # If the pattern is inverted, flip the stride\n",
    "    if value_20 < value_80:\n",
    "        stride_data = -stride_data\n",
    "    return stride_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6cf96-9d83-457b-b64b-595c4d3a49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_processed_strides(strides_r, strides_l, header, header_type, plot_style='single'):\n",
    "    \"\"\"\n",
    "    Plots the processed strides for the given header and header type.\n",
    "\n",
    "    Parameters:\n",
    "    - strides_r: list of stride_info dictionaries for the right side (or None)\n",
    "    - strides_l: list of stride_info dictionaries for the left side (or None)\n",
    "    - header: the header name\n",
    "    - header_type: 'bilateral', 'right_only', 'left_only'\n",
    "    - plot_style: 'single' or 'side_by_side' (optional, default is 'single')\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Begin plotting\n",
    "    if header_type == 'bilateral':\n",
    "        if plot_style == 'single':\n",
    "            plt.figure()\n",
    "            # Plot right processed strides in red\n",
    "            if strides_r is not None:\n",
    "                for stride_info in strides_r:\n",
    "                    stride_data = stride_info['processed_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))  # Stride percentage\n",
    "                    plt.plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "            # Plot left processed strides in blue\n",
    "            if strides_l is not None:\n",
    "                for stride_info in strides_l:\n",
    "                    stride_data = stride_info['processed_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                    plt.plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "            plt.title(f'Processed Bilateral Strides - {header}')\n",
    "            plt.xlabel('Stride Percentage (%)')\n",
    "            plt.ylabel(header)\n",
    "            plt.legend(['Right Processed Strides', 'Left Processed Strides'])\n",
    "            plt.show()\n",
    "        elif plot_style == 'side_by_side':\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            # Plot right processed strides\n",
    "            if strides_r is not None:\n",
    "                for stride_info in strides_r:\n",
    "                    stride_data = stride_info['processed_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                    axs[0].plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "                axs[0].set_title(f'Processed Right Strides - {header}')\n",
    "                axs[0].set_xlabel('Stride Percentage (%)')\n",
    "                axs[0].set_ylabel(header)\n",
    "            # Plot left processed strides\n",
    "            if strides_l is not None:\n",
    "                for stride_info in strides_l:\n",
    "                    stride_data = stride_info['processed_stride_data']\n",
    "                    x_values = np.linspace(0, 100, len(stride_data))\n",
    "                    axs[1].plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "                axs[1].set_title(f'Processed Left Strides - {header}')\n",
    "                axs[1].set_xlabel('Stride Percentage (%)')\n",
    "                axs[1].set_ylabel(header)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    elif header_type == 'right_only':\n",
    "        plt.figure()\n",
    "        if strides_r is not None:\n",
    "            for stride_info in strides_r:\n",
    "                stride_data = stride_info['processed_stride_data']\n",
    "                x_values = np.linspace(0, 100, len(stride_data))\n",
    "                plt.plot(x_values, stride_data, color='red', alpha=0.5)\n",
    "        plt.title(f'Processed Right Strides - {header}')\n",
    "        plt.xlabel('Stride Percentage (%)')\n",
    "        plt.ylabel(header)\n",
    "        plt.legend(['Right Processed Strides'])\n",
    "        plt.show()\n",
    "    elif header_type == 'left_only':\n",
    "        plt.figure()\n",
    "        if strides_l is not None:\n",
    "            for stride_info in strides_l:\n",
    "                stride_data = stride_info['processed_stride_data']\n",
    "                x_values = np.linspace(0, 100, len(stride_data))\n",
    "                plt.plot(x_values, stride_data, color='blue', alpha=0.5)\n",
    "        plt.title(f'Processed Left Strides - {header}')\n",
    "        plt.xlabel('Stride Percentage (%)')\n",
    "        plt.ylabel(header)\n",
    "        plt.legend(['Left Processed Strides'])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139157ed-e4dc-48db-b722-b7ee5aff4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script to process all trials\n",
    "strideList_dict = {}\n",
    "#for trial in range(1, 22): Mod for simplification. \n",
    "for trial in range(16,22): #Participants\n",
    "    current_folderpath = Path(folderpath) / f\"{trial:02d}\"\n",
    "    current_HeelPath = HeelPathTemplate.format(f\"{trial:02d}\")\n",
    "    mot_files = list((current_folderpath / 'IKResults').glob(\"*.mot\"))\n",
    "    json_save_path = os.path.join(base_json_path, f\"Subject{trial:02d}.json\")\n",
    "    participant_id = f\"Participant_{trial:02d}\"  \n",
    "    print('Participant ID: ', participant_id)\n",
    "    strideList_dict[participant_id] = {}\n",
    "    \n",
    "    \n",
    "    for file_path in mot_files: #Participants trials\n",
    "        print('Current File path: ', file_path)\n",
    "        file_path_str = str(file_path)\n",
    "        data = pd.read_csv(file_path, sep='\\t', header=header_line)\n",
    "        current_headers = data.columns\n",
    "        \n",
    "        # Extract trial name from file path\n",
    "        match = re.search(pattern, file_path_str)\n",
    "        if match:\n",
    "            trial_name = match.group(1)\n",
    "            print ('Processing Trial:', trial_name)\n",
    "            print('HeelFilePath: ', current_HeelPath)\n",
    "            # Check if trial exists in the HDF5 file\n",
    "            with h5py.File(current_HeelPath, 'r') as file:\n",
    "                print('HeelFilePath: ', current_HeelPath)\n",
    "                if trial_name in file['NexusData']:\n",
    "                    heels_r = []\n",
    "                    heels_l = []\n",
    "                    toes_r = []\n",
    "                    toes_l = []\n",
    "                    \n",
    "                    try:\n",
    "                        # Attempt to load heels and toes data\n",
    "                        for side in ['Right', 'Left']:\n",
    "                            try:\n",
    "                                # Try accessing data in the original structure\n",
    "                                if isinstance(file['NexusData'][trial_name][side]['heels'], h5py.Dataset):\n",
    "                                    if side == 'Right':\n",
    "                                        nexus_data_r = file['NexusData'][trial_name][side]['heels'][:]\n",
    "                                    else:\n",
    "                                        nexus_data_l = file['NexusData'][trial_name][side]['heels'][:]\n",
    "                                    print(f'{side} Heels loaded in original structure.')\n",
    "                                else:\n",
    "                                    # If its a group, try accessing the inner dataset\n",
    "                                    if side == 'Right':\n",
    "                                        nexus_data_r = file['NexusData'][trial_name][side]['heels']['heels'][:]\n",
    "                                    else:\n",
    "                                        nexus_data_l = file['NexusData'][trial_name][side]['heels']['heels'][:]\n",
    "                                    print(f'{side} Heels loaded in alternative structure: [\"heels\"][\"heels\"].')\n",
    "        \n",
    "                            except KeyError:\n",
    "                                print(f'Error: {side} Heels not found for trial {trial_name}')\n",
    "        \n",
    "                            try:\n",
    "                                # Try accessing data in the original structure for Toes\n",
    "                                if isinstance(file['NexusData'][trial_name][side]['Toes'], h5py.Dataset):\n",
    "                                    if side == 'Right':\n",
    "                                        nexus_toes_r = file['NexusData'][trial_name][side]['Toes'][:]\n",
    "                                    else:\n",
    "                                        nexus_toes_l = file['NexusData'][trial_name][side]['Toes'][:]\n",
    "                                    print(f'{side} Toes loaded in original structure.')\n",
    "                                else:\n",
    "                                    # If its a group, try accessing the inner dataset\n",
    "                                    if side == 'Right':\n",
    "                                        nexus_toes_r = file['NexusData'][trial_name][side]['Toes']['Toes'][:]\n",
    "                                    else:\n",
    "                                        nexus_toes_l = file['NexusData'][trial_name][side]['Toes']['Toes'][:]\n",
    "                                    print(f'{side} Toes loaded in alternative structure: [\"Toes\"][\"Toes\"].')\n",
    "        \n",
    "                            except KeyError:\n",
    "                                print(f'Error: {side} Toes not found for trial {trial_name}')\n",
    "                                \n",
    "                    except KeyError: #this one\n",
    "                            print(f'Error: {side} Toes not found for trial {trial_name}')\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    # Process Heel - Toe data\n",
    "                    ROI = get_ROI(file,trial_name)\n",
    "                    sampling = get_sampling_rate(file,trial_name)\n",
    "                    print('sampling rate: ', sampling)\n",
    "                    #get rid of events outside ROI\n",
    "                    # Filter events\n",
    "                    heels_r_filtered = filter_events_within_roi(nexus_data_r, ROI, sampling)\n",
    "                    heels_l_filtered = filter_events_within_roi(nexus_data_l, ROI, sampling)\n",
    "                    toes_r_filtered = filter_events_within_roi(nexus_toes_r, ROI, sampling)\n",
    "                    toes_l_filtered = filter_events_within_roi(nexus_toes_l, ROI, sampling)\n",
    "                    print('Heels Filtered', heels_r_filtered)\n",
    "\n",
    "                    heels_r_times = indices_to_time(heels_r_filtered, sampling_rate=sampling)\n",
    "                    heels_l_times = indices_to_time(heels_l_filtered, sampling_rate=sampling)\n",
    "                    toes_r_times = indices_to_time(toes_r_filtered, sampling_rate=sampling)\n",
    "                    toes_l_times = indices_to_time(toes_l_filtered, sampling_rate=sampling)                    \n",
    "                    #####################################\n",
    "                    heels_r_sorted = sorted(heels_r_times)\n",
    "                    heels_l_sorted = sorted(heels_l_times)\n",
    "                    toes_r_sorted = sorted(toes_r_times)\n",
    "                    toes_l_sorted = sorted(toes_l_times)\n",
    "                    \n",
    "                    # Combine all event times for x-axis limits\n",
    "                    all_event_times = heels_r_sorted + heels_l_sorted + toes_r_sorted + toes_l_sorted\n",
    "                    \n",
    "                    if all_event_times:\n",
    "                        min_time = min(all_event_times)\n",
    "                        max_time = max(all_event_times)\n",
    "                    else:\n",
    "                        print(\"No events to plot.\")\n",
    "                        min_time = 0\n",
    "                        max_time = 1  # Set default values or handle as needed\n",
    "                    \n",
    "                    plt.figure(figsize=(15, 5))\n",
    "                    # Plot Right Heel Contacts\n",
    "                    if heels_r_sorted:\n",
    "                        plt.scatter(heels_r_sorted, [1]*len(heels_r_sorted), marker='^', color='blue', label='Right Heel Contact')\n",
    "                    # Plot Left Heel Contacts\n",
    "                    if heels_l_sorted:\n",
    "                        plt.scatter(heels_l_sorted, [1]*len(heels_l_sorted), marker='^', color='red', label='Left Heel Contact')\n",
    "                    \n",
    "                    # Plot Right Toe-Offs\n",
    "                    if toes_r_sorted:\n",
    "                        plt.scatter(toes_r_sorted, [0]*len(toes_r_sorted), marker='v', color='blue', label='Right Toe-Off')\n",
    "                    \n",
    "                    # Plot Left Toe-Offs\n",
    "                    if toes_l_sorted:\n",
    "                        plt.scatter(toes_l_sorted, [0]*len(toes_l_sorted), marker='v', color='red', label='Left Toe-Off')\n",
    "                    \n",
    "                    # Adjust y positions slightly for visualization\n",
    "                    plt.yticks([0, 1], ['Toe-Off', 'Heel Contact'])\n",
    "                    \n",
    "                    # Add vertical lines for visualization\n",
    "                    for t in heels_r_sorted:\n",
    "                        plt.axvline(x=t, color='blue', linestyle='--', alpha=0.3)\n",
    "                    for t in heels_l_sorted:\n",
    "                        plt.axvline(x=t, color='red', linestyle='--', alpha=0.3)\n",
    "                    for t in toes_r_sorted:\n",
    "                        plt.axvline(x=t, color='blue', linestyle=':', alpha=0.3)\n",
    "                    for t in toes_l_sorted:\n",
    "                        plt.axvline(x=t, color='red', linestyle=':', alpha=0.3)\n",
    "                    \n",
    "                    # Customize the plot\n",
    "                    plt.xlabel('Time (seconds)')\n",
    "                    plt.ylabel('Event Type')\n",
    "                    plt.title(f'Gait Events Timeline for Trial {trial_name}')\n",
    "                    plt.legend(loc='upper right')\n",
    "                    plt.xlim([min_time - 0.5, max_time + 0.5])\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "                    ##################################### Stride Segmentation and Normalisation\n",
    "                    # Process strides for each header\n",
    "                    bilateral_headers = []\n",
    "                    right_only_headers = []\n",
    "                    left_only_headers = []\n",
    "                    trial_processed_strides = {}\n",
    "                    for header in data.columns:\n",
    "                        if header.endswith('_r'):\n",
    "                            right_only_headers.append(header)\n",
    "                        elif header.endswith('_l'):\n",
    "                            left_only_headers.append(header)\n",
    "                        else:\n",
    "                            bilateral_headers.append(header)\n",
    "\n",
    "                    for header in bilateral_headers:\n",
    "                        print('Processing bilateral header:', header)\n",
    "                        # Process for right strides\n",
    "                        strides_r = process_side_strides(\n",
    "                            ipsi_heels=heels_r_times,\n",
    "                            ipsi_toes=toes_r_times,\n",
    "                            contra_heels=heels_l_times,\n",
    "                            contra_toes=toes_l_times,\n",
    "                            header=header,\n",
    "                            data=data\n",
    "                        )\n",
    "                        strides_r = normalize_strides(strides_r, normalization_type='cycle', target_length=100)\n",
    "                        \n",
    "                        # Process for left strides\n",
    "                        strides_l = process_side_strides(\n",
    "                            ipsi_heels=heels_l_times,\n",
    "                            ipsi_toes=toes_l_times,\n",
    "                            contra_heels=heels_r_times,\n",
    "                            contra_toes=toes_r_times,\n",
    "                            header=header,\n",
    "                            data=data\n",
    "                        )\n",
    "                        strides_l = normalize_strides(strides_l, normalization_type='cycle', target_length=100)\n",
    "\n",
    "                        strides_r, strides_l = apply_conventions(strides_r, strides_l, header)\n",
    "                        \n",
    "                        #plot_strides(strides_r, strides_l, header, 'bilateral', plot_style='single')\n",
    "\n",
    "                        trial_processed_strides[header] = {\n",
    "                            'strides_r': strides_r,\n",
    "                            'strides_l': strides_l,\n",
    "                            'header_type': 'bilateral'\n",
    "                        }\n",
    "\n",
    "                    \n",
    "                    for header in right_only_headers:\n",
    "                        print('Processing right-only header:', header)\n",
    "                        # Process for right strides\n",
    "                        strides_r = process_side_strides(\n",
    "                            ipsi_heels=heels_r_times,\n",
    "                            ipsi_toes=toes_r_times,\n",
    "                            contra_heels=heels_l_times,\n",
    "                            contra_toes=toes_l_times,\n",
    "                            header=header,\n",
    "                            data=data\n",
    "                        )\n",
    "                        strides_r = normalize_strides(strides_r, normalization_type='cycle', target_length=100)\n",
    "                        strides_r, _ = apply_conventions(strides_r, None, header)\n",
    "                        #plot_strides(strides_r, None, header, 'right_only')\n",
    "                        trial_processed_strides[header] = {\n",
    "                            'strides_r': strides_r,\n",
    "                            'strides_l': None,\n",
    "                            'header_type': 'right_only'\n",
    "                        }\n",
    "\n",
    "                    \n",
    "                    for header in left_only_headers:\n",
    "                        print('Processing left-only header:', header)\n",
    "                        # Process for left strides\n",
    "                        strides_l = process_side_strides(\n",
    "                            ipsi_heels=heels_l_times,\n",
    "                            ipsi_toes=toes_l_times,\n",
    "                            contra_heels=heels_r_times,\n",
    "                            contra_toes=toes_r_times,\n",
    "                            header=header,\n",
    "                            data=data\n",
    "                        )\n",
    "                        strides_l = normalize_strides(strides_l, normalization_type='cycle', target_length=100)\n",
    "                        _, strides_l = apply_conventions(None, strides_l, header)\n",
    "                        #plot_strides(None, strides_l, header, 'left_only')\n",
    "                    \n",
    "                        trial_processed_strides[header] = {\n",
    "                            'strides_r': None,\n",
    "                            'strides_l': strides_l,\n",
    "                            'header_type': 'left_only'\n",
    "                        }\n",
    "\n",
    "\n",
    "                    for header, stride_data in trial_processed_strides.items():\n",
    "                        strides_r = stride_data['strides_r']\n",
    "                        strides_l = stride_data['strides_l']\n",
    "                        header_type = stride_data['header_type']\n",
    "                        plot_processed_strides(strides_r, strides_l, header, header_type, plot_style='single')\n",
    "                    \n",
    "\n",
    "                    \n",
    "    \n",
    "                    \n",
    "                    # Store trial processed strides under participant and trial\n",
    "                    strideList_dict[participant_id][trial_name] = trial_processed_strides\n",
    "                    for header, stride_data in trial_processed_strides.items():\n",
    "                        strides_r = stride_data['strides_r']\n",
    "                        strides_l = stride_data['strides_l']\n",
    "                        header_type = stride_data['header_type']\n",
    "                    \n",
    "                        # Initialize a new figure\n",
    "                        plt.figure()\n",
    "                    \n",
    "                        # Plot right strides\n",
    "                        if strides_r:\n",
    "                            mean_stride_r, lower_r, upper_r = compute_mean_and_variability(strides_r, variability='CI')\n",
    "                            plot_mean_and_variability(mean_stride_r, lower_r, upper_r, header, 'Right', 'red')\n",
    "                    \n",
    "                        # Plot left strides\n",
    "                        if strides_l:\n",
    "                            mean_stride_l, lower_l, upper_l = compute_mean_and_variability(strides_l, variability='CI')\n",
    "                            plot_mean_and_variability(mean_stride_l, lower_l, upper_l, header, 'Left', 'blue')\n",
    "                    \n",
    "                        # Set the title and show the plot\n",
    "                        plt.title(f'{header} - Mean and Variability')\n",
    "                        plt.xlabel('Stride Percentage (%)')\n",
    "                        plt.ylabel(header)\n",
    "                        plt.legend()\n",
    "                        plt.show()\n",
    "            #raise Exception(\"Stopping script for testing.\")\n",
    "    save_participant_strides(strideList_dict, participant_id, current_folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b48d8-392f-4cea-b1c3-92ca58bdcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_and_variability(strides_list, variability='SD'):\n",
    "    \"\"\"\n",
    "    Computes the mean stride and variability (SD, SE, or 95% CI) across a list of strides.\n",
    "\n",
    "    Parameters:\n",
    "    - strides_list: List of stride_info dictionaries containing 'processed_stride_data'.\n",
    "    - variability: Type of variability to compute ('SD', 'SE', 'CI').\n",
    "\n",
    "    Returns:\n",
    "    - mean_stride: Numpy array of the mean stride.\n",
    "    - lower_bound: Numpy array of the lower bound of the variability area.\n",
    "    - upper_bound: Numpy array of the upper bound of the variability area.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if not strides_list:\n",
    "        return None, None, None\n",
    "\n",
    "    # Collect all processed stride data\n",
    "    stride_data_list = [stride_info['processed_stride_data'] for stride_info in strides_list]\n",
    "    # Stack stride data into a 2D array (strides x data points)\n",
    "    stride_data_array = np.stack(stride_data_list, axis=0)\n",
    "    # Compute the mean across strides\n",
    "    mean_stride = np.mean(stride_data_array, axis=0)\n",
    "\n",
    "    # Compute variability\n",
    "    if variability == 'SD':\n",
    "        var_stride = np.std(stride_data_array, axis=0)\n",
    "        lower_bound = mean_stride - var_stride\n",
    "        upper_bound = mean_stride + var_stride\n",
    "    elif variability == 'SE':\n",
    "        var_stride = np.std(stride_data_array, axis=0) / np.sqrt(stride_data_array.shape[0])\n",
    "        lower_bound = mean_stride - var_stride\n",
    "        upper_bound = mean_stride + var_stride\n",
    "    elif variability == 'CI':\n",
    "        from scipy import stats\n",
    "        confidence = 0.95\n",
    "        n = stride_data_array.shape[0]\n",
    "        stderr = stats.sem(stride_data_array, axis=0)\n",
    "        t_value = stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "        margin_of_error = t_value * stderr\n",
    "        lower_bound = mean_stride - margin_of_error\n",
    "        upper_bound = mean_stride + margin_of_error\n",
    "    else:\n",
    "        raise ValueError(\"Invalid variability type. Choose 'SD', 'SE', or 'CI'.\")\n",
    "\n",
    "    return mean_stride, lower_bound, upper_bound\n",
    "\n",
    "\n",
    "def plot_mean_and_variability(mean_stride, lower_bound, upper_bound, header, side_label, color):\n",
    "    \"\"\"\n",
    "    Plots the mean stride and variability area.\n",
    "\n",
    "    Parameters:\n",
    "    - mean_stride: Numpy array of the mean stride.\n",
    "    - lower_bound: Numpy array of the lower bound of the variability area.\n",
    "    - upper_bound: Numpy array of the upper bound of the variability area.\n",
    "    - header: The parameter name (string) being plotted.\n",
    "    - side_label: Label for the side ('Right' or 'Left').\n",
    "    - color: Color for the plot.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if mean_stride is None:\n",
    "        return\n",
    "\n",
    "    x_values = np.linspace(0, 100, len(mean_stride))  # Stride percentage\n",
    "\n",
    "    plt.plot(x_values, mean_stride, color=color, label=f'{side_label} Mean')\n",
    "    plt.fill_between(x_values, lower_bound, upper_bound, color=color, alpha=0.3, label=f'{side_label} Variability')\n",
    "    plt.xlabel('Stride Percentage (%)')\n",
    "    plt.ylabel(header)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4bc7b-dbda-4052-a872-4d91757a5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_participant_strides(strideList_dict, participant_id, participant_folderpath):\n",
    "    \"\"\"\n",
    "    Saves the participant's concatenated strides into the Kinematics folder.\n",
    "\n",
    "    Parameters:\n",
    "    - strideList_dict: Dictionary containing all participants' strides.\n",
    "    - participant_id: String identifier for the participant.\n",
    "    - participant_folderpath: Path object of the participant's folder.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    # Access the participant's data from strideList_dict\n",
    "    participant_data = strideList_dict[participant_id]\n",
    "\n",
    "    # Initialize a dictionary to store concatenated strides across trials\n",
    "    participant_concatenated_strides = {}\n",
    "\n",
    "    # Iterate over trials and concatenate strides\n",
    "    for trial_name, trial_processed_strides in participant_data.items():\n",
    "        for header, stride_data in trial_processed_strides.items():\n",
    "            # Initialize the header in participant_concatenated_strides if not already present\n",
    "            if header not in participant_concatenated_strides:\n",
    "                participant_concatenated_strides[header] = {\n",
    "                    'strides_r': [],\n",
    "                    'strides_l': [],\n",
    "                    'header_type': stride_data['header_type']\n",
    "                }\n",
    "\n",
    "            # Extend the participant's strides with the strides from this trial\n",
    "            if stride_data['strides_r']:\n",
    "                participant_concatenated_strides[header]['strides_r'].extend(stride_data['strides_r'])\n",
    "            if stride_data['strides_l']:\n",
    "                participant_concatenated_strides[header]['strides_l'].extend(stride_data['strides_l'])\n",
    "\n",
    "    # Define the path to the Kinematics folder\n",
    "    kinematics_folder = participant_folderpath / 'Kinematics'\n",
    "\n",
    "    # Create the Kinematics folder if it doesn't exist\n",
    "    if not kinematics_folder.exists():\n",
    "        os.makedirs(kinematics_folder)\n",
    "        print(f\"Created Kinematics folder at {kinematics_folder}\")\n",
    "\n",
    "    # Define the file path to save the strides\n",
    "    strides_file_path = kinematics_folder / 'concatenated_strides.pkl'\n",
    "\n",
    "    # Save the participant_concatenated_strides dictionary to the file\n",
    "    with open(strides_file_path, 'wb') as f:\n",
    "        pickle.dump(participant_concatenated_strides, f)\n",
    "\n",
    "    print(f\"Saved concatenated strides to {strides_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cae6ef-5bdd-42b4-a4ff-ea50fac410dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300875c-9cbb-4e60-a399-19d385e9764a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de46c5ae-45cf-4311-9380-0d413536d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "try:\n",
    "    mat_data = loadmat(current_HeelPath)\n",
    "    print(\"Successfully loaded data using `loadmat`.\")\n",
    "    # You can then explore the keys in the file to understand its structure\n",
    "    print(mat_data.keys())\n",
    "except NotImplementedError:\n",
    "    print(f\"Error: The file '{current_HeelPath}' may be saved in a newer HDF5-compatible format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load '{current_HeelPath}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b443e-c503-44a9-80e9-facbe0fce27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
